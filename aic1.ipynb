{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (C:/Users/Omar/.cache/huggingface/datasets/csv/default-f3637b5a9b9def03/0.0.0/eea64c71ca8b46dd3f537ed218fc9bf495d5707789152eb2764f5c78fa66d59d)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbd5742be47f4b05b6faa54c0b718b6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset('csv', data_files={'train':'train.csv', 'validation':'validation.csv', 'test':'test.csv'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'يعزا تراجع إيرادات ياهو بشكل كبير إلى الانخفاض الحاد في نشاط الإعلانات المرئية الرقمية وتساعد فلاري مطوري التطبيقات على تحليل البيانات المتعلقة بمستخدميهم وتوفير إعلانات تناسب أذواقهم. واشترى بعض منافسي ياهو شركات تعمل في تكنولوجيا إعلانات الهواتف المحمولة في محاولة لجذب المسوقين إلى تطبيقاتها وتحقيق إيرادات من الإعلانات على تطبيقات شركات أخرى. ولم تكشف الشركتان عن البنود المالية لصفقة الاستحواذ. لكن بعض التقارير أشارت إلى أن ياهو دفعت ما بين 200 و300 مليون دولار للاستحواذ على فلاري، لتكون بذلك واحدة من أكبر عمليات الاستحواذ لياهو منذ أن استحوذت على منصة تدوين \"تومبير\" عام 2012. مواضيع قد تهمك نهاية تعزيز الإيرادات وتأتي صفقة ياهو للاستحواذ على فلاري بعد أيام فقط من إعلان تراجع أرباحها بواقع 18 في المئة إلى 270 مليون دولار خلال الأشهر الثلاثة حتى نهاية يونيو/حزيران الماضي. وتراجعت الإيرادات أيضا في شركة الانترنت العملاقة بواقع ثلاثة في المئة إلى 1.08 مليار دولار. ويعزا هذا التراجع بشكل كبير إلى الانخفاض الحاد في نشاط الإعلانات المرئية الرقمية، التي تراجعت بواقع ثمانية في المئة في الربع الثاني. لكن ياهو قالت إن إيرادات إعلانات الهواتف المحمولة وأنشطة البحث زاد كل منها بأكثر من 100 في المئة خلال هذه الفترة مقارنة بالعام السابق. وقالت الشركتان الاثنين إنه من خلال اندماجهما معا فسيكونان أكثر قدرة على خدمة عملائهما بصورة أفضل وتعزيز إيرادات الإعلانات. ماريسا ماير الرئيسة التنفيذية لياهو تقول إن الشركة تحتاج للعمل بجد لوقف تراجع إيرادات الإعلانات التركيز على الهواتف المحمولة وقال سيمون خلف الرئيس التنفيذي لشركة فلاري في بيان له إنه \"بالتعاون مع ياهو، سيكون بإمكاننا الاستفادة من المزيد من الموارد لتسريع تقديم منتجات رائعة يمكن أن تساعد المطورين على ابتكار تطبيقات أفضل والوصول إلى المستخدمين المناسبين واكتشاف فرص جديدة لتحقيق الإيرادات\". وبحسب موقع فلاري على الانترنت، فإنها تعمل مع أكثر من 170 ألف مطور يحصلون على بيانات من خلال متابعة 150 مليار من اتصالات التطبيقات شهريا لتوفير معلومات لشركات نشر التطبيقات تتعلق بجمهورها واستخدام التطبيق ومستوى أدائه. وتزايد الطلب العالمي على الهواتف المحمولة خلال السنوات الأخيرة وتزايد عدد الأشخاص الذين يدخلون إلى الانترنت من خلال هواتفهم الذكية في مقابل أجهزة الكمبيوتر الشخصية التقليدية. ودفع هذا شركات الانترنت مثل ياهو وتويتر وغوغل وفيسبوك لتطوير استراتيجيات لزيادة إيراداتها من الهواتف المحمولة.',\n",
       " 'summary': 'استحوذت شركة ياهو على شركة فلاري لتحليل التطبيقات للمساعدة في تعزيز عائداتها من الإعلانات من الهواتف الذكية.'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "from arabert.preprocess import ArabertPreprocessor\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-07-03 01:26:14,325 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"aubmindlab/bert-base-arabertv2\"\n",
    "preprocessor = ArabertPreprocessor(model_name=model_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "  return preprocessor.preprocess(text)\n",
    "\n",
    "\n",
    "import re\n",
    "\n",
    "def clean(text):\n",
    "  temp = preprocessor.unpreprocess(text)\n",
    "  temp = re.sub('\\[CLS\\]|\\[PAD\\]|\\[SEP\\]', '', temp)\n",
    "  return re.sub('\\s+$|^\\s', '', temp)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"./AraT5\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"./AraT5\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encode the dataset with the tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "  inputs = examples['text']\n",
    "  model_inputs = tokenizer(inputs, padding='max_length', truncation=True)\n",
    "\n",
    "  labels = tokenizer(examples['summary'], padding='max_length', max_length=128, truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "  model_inputs['labels'] = labels['input_ids']\n",
    "  return model_inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\Omar\\.cache\\huggingface\\datasets\\csv\\default-f3637b5a9b9def03\\0.0.0\\eea64c71ca8b46dd3f537ed218fc9bf495d5707789152eb2764f5c78fa66d59d\\cache-5e1fa4d7692cd808.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61320bc061f04b3ba0651af1b6f086f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7610 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to pad to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no padding.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Loading cached processed dataset at C:\\Users\\Omar\\.cache\\huggingface\\datasets\\csv\\default-f3637b5a9b9def03\\0.0.0\\eea64c71ca8b46dd3f537ed218fc9bf495d5707789152eb2764f5c78fa66d59d\\cache-6af0c8841cf8817b.arrow\n",
      "Loading cached shuffled indices for dataset at C:\\Users\\Omar\\.cache\\huggingface\\datasets\\csv\\default-f3637b5a9b9def03\\0.0.0\\eea64c71ca8b46dd3f537ed218fc9bf495d5707789152eb2764f5c78fa66d59d\\cache-0ef5ba1d0dade5cb.arrow\n",
      "Loading cached shuffled indices for dataset at C:\\Users\\Omar\\.cache\\huggingface\\datasets\\csv\\default-f3637b5a9b9def03\\0.0.0\\eea64c71ca8b46dd3f537ed218fc9bf495d5707789152eb2764f5c78fa66d59d\\cache-51f7f1f9d8ea868e.arrow\n"
     ]
    }
   ],
   "source": [
    "tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "small_train_dataset = tokenized_dataset[\"train\"].shuffle(seed=42).select(range(1000))\n",
    "small_test_dataset = tokenized_dataset[\"test\"].shuffle(seed=42).select(range(1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "import numpy as np\n",
    "\n",
    "rouge = evaluate.load('rouge')\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    result = rouge.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
    "\n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "\n",
    "    return {k: round(v, 4) for k, v in result.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import torch\n",
    "# torch.cuda.is_available()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"finetuned-model\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=4,\n",
    "    predict_with_generate=True\n",
    "    # fp16=True\n",
    ")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=small_train_dataset,\n",
    "    eval_dataset=small_test_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
