{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (C:/Users/Omar/.cache/huggingface/datasets/csv/default-80bb726c2d57ffc1/0.0.0/eea64c71ca8b46dd3f537ed218fc9bf495d5707789152eb2764f5c78fa66d59d)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51bcb598f20e46bcbcaa71c530070b0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset('csv', data_files={'train':'train.csv', 'validation':'validation.csv', 'test':'test.csv'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'يعزا تراجع إيرادات ياهو بشكل كبير إلى الانخفاض الحاد في نشاط الإعلانات المرئية الرقمية وتساعد فلاري مطوري التطبيقات على تحليل البيانات المتعلقة بمستخدميهم وتوفير إعلانات تناسب أذواقهم. واشترى بعض منافسي ياهو شركات تعمل في تكنولوجيا إعلانات الهواتف المحمولة في محاولة لجذب المسوقين إلى تطبيقاتها وتحقيق إيرادات من الإعلانات على تطبيقات شركات أخرى. ولم تكشف الشركتان عن البنود المالية لصفقة الاستحواذ. لكن بعض التقارير أشارت إلى أن ياهو دفعت ما بين 200 و300 مليون دولار للاستحواذ على فلاري، لتكون بذلك واحدة من أكبر عمليات الاستحواذ لياهو منذ أن استحوذت على منصة تدوين \"تومبير\" عام 2012. مواضيع قد تهمك نهاية تعزيز الإيرادات وتأتي صفقة ياهو للاستحواذ على فلاري بعد أيام فقط من إعلان تراجع أرباحها بواقع 18 في المئة إلى 270 مليون دولار خلال الأشهر الثلاثة حتى نهاية يونيو/حزيران الماضي. وتراجعت الإيرادات أيضا في شركة الانترنت العملاقة بواقع ثلاثة في المئة إلى 1.08 مليار دولار. ويعزا هذا التراجع بشكل كبير إلى الانخفاض الحاد في نشاط الإعلانات المرئية الرقمية، التي تراجعت بواقع ثمانية في المئة في الربع الثاني. لكن ياهو قالت إن إيرادات إعلانات الهواتف المحمولة وأنشطة البحث زاد كل منها بأكثر من 100 في المئة خلال هذه الفترة مقارنة بالعام السابق. وقالت الشركتان الاثنين إنه من خلال اندماجهما معا فسيكونان أكثر قدرة على خدمة عملائهما بصورة أفضل وتعزيز إيرادات الإعلانات. ماريسا ماير الرئيسة التنفيذية لياهو تقول إن الشركة تحتاج للعمل بجد لوقف تراجع إيرادات الإعلانات التركيز على الهواتف المحمولة وقال سيمون خلف الرئيس التنفيذي لشركة فلاري في بيان له إنه \"بالتعاون مع ياهو، سيكون بإمكاننا الاستفادة من المزيد من الموارد لتسريع تقديم منتجات رائعة يمكن أن تساعد المطورين على ابتكار تطبيقات أفضل والوصول إلى المستخدمين المناسبين واكتشاف فرص جديدة لتحقيق الإيرادات\". وبحسب موقع فلاري على الانترنت، فإنها تعمل مع أكثر من 170 ألف مطور يحصلون على بيانات من خلال متابعة 150 مليار من اتصالات التطبيقات شهريا لتوفير معلومات لشركات نشر التطبيقات تتعلق بجمهورها واستخدام التطبيق ومستوى أدائه. وتزايد الطلب العالمي على الهواتف المحمولة خلال السنوات الأخيرة وتزايد عدد الأشخاص الذين يدخلون إلى الانترنت من خلال هواتفهم الذكية في مقابل أجهزة الكمبيوتر الشخصية التقليدية. ودفع هذا شركات الانترنت مثل ياهو وتويتر وغوغل وفيسبوك لتطوير استراتيجيات لزيادة إيراداتها من الهواتف المحمولة.',\n",
       " 'summary': 'استحوذت شركة ياهو على شركة فلاري لتحليل التطبيقات للمساعدة في تعزيز عائداتها من الإعلانات من الهواتف الذكية.'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "from arabert.preprocess import ArabertPreprocessor\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-07-02 22:10:11,702 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"aubmindlab/bert-base-arabertv2\"\n",
    "preprocessor = ArabertPreprocessor(model_name=model_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "  return preprocessor.preprocess(text)\n",
    "\n",
    "\n",
    "import re\n",
    "\n",
    "def clean(text):\n",
    "  temp = preprocessor.unpreprocess(text)\n",
    "  temp = re.sub('\\[CLS\\]|\\[PAD\\]|\\[SEP\\]', '', temp)\n",
    "  return re.sub('\\s+$|^\\s', '', temp)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"./AraT5\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"./AraT5\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encode the dataset with the tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "  inputs = examples['text']\n",
    "  model_inputs = tokenizer(inputs, padding='max_length', truncation=True)\n",
    "\n",
    "  labels = tokenizer(examples['summary'], padding='max_length', max_length=128, truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "  model_inputs['labels'] = labels['input_ids']\n",
    "  return model_inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09ad0617dbb349548adcb182d9a0de70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/60878 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to pad to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no padding.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "380c487bbdbd4c7f8cb5b28eb0f466f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7610 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b169973ce9cd476db82b874135b0360f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7610 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "small_train_dataset = tokenized_dataset[\"train\"].shuffle(seed=42).select(range(1000))\n",
    "small_test_dataset = tokenized_dataset[\"test\"].shuffle(seed=42).select(range(1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "To be able to use evaluate-metric/rouge, you need to install the following dependencies['absl', 'rouge_score'] using 'pip install # Here to have a nice missing dependency error message early on rouge_score' for instance'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19240\\2076020932.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mrouge\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'rouge'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mcompute_metrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meval_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Omar\\anaconda3\\lib\\site-packages\\evaluate\\loading.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(path, config_name, module_type, process_id, num_process, cache_dir, experiment_id, keep_in_memory, download_config, download_mode, revision, **init_kwargs)\u001b[0m\n\u001b[0;32m    729\u001b[0m     \"\"\"\n\u001b[0;32m    730\u001b[0m     \u001b[0mdownload_mode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDownloadMode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdownload_mode\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mDownloadMode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mREUSE_DATASET_IF_EXISTS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 731\u001b[1;33m     evaluation_module = evaluation_module_factory(\n\u001b[0m\u001b[0;32m    732\u001b[0m         \u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodule_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodule_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrevision\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrevision\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdownload_config\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdownload_config\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdownload_mode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdownload_mode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    733\u001b[0m     )\n",
      "\u001b[1;32mc:\\Users\\Omar\\anaconda3\\lib\\site-packages\\evaluate\\loading.py\u001b[0m in \u001b[0;36mevaluation_module_factory\u001b[1;34m(path, module_type, revision, download_config, download_mode, force_local_path, dynamic_modules_path, **download_kwargs)\u001b[0m\n\u001b[0;32m    678\u001b[0m                     \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    679\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mConnectionError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 680\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0me1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    681\u001b[0m             raise FileNotFoundError(\n\u001b[0;32m    682\u001b[0m                 \u001b[1;34mf\"Couldn't find a module script at {relative_to_absolute_path(combined_path)}. \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Omar\\anaconda3\\lib\\site-packages\\evaluate\\loading.py\u001b[0m in \u001b[0;36mevaluation_module_factory\u001b[1;34m(path, module_type, revision, download_config, download_mode, force_local_path, dynamic_modules_path, **download_kwargs)\u001b[0m\n\u001b[0;32m    631\u001b[0m                     \u001b[1;32mfor\u001b[0m \u001b[0mcurrent_type\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"metric\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"comparison\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"measurement\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    632\u001b[0m                         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 633\u001b[1;33m                             return HubEvaluationModuleFactory(\n\u001b[0m\u001b[0;32m    634\u001b[0m                                 \u001b[1;34mf\"evaluate-{current_type}/{path}\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    635\u001b[0m                                 \u001b[0mrevision\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrevision\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Omar\\anaconda3\\lib\\site-packages\\evaluate\\loading.py\u001b[0m in \u001b[0;36mget_module\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    487\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m         \u001b[0mimports\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_imports\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlocal_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 489\u001b[1;33m         local_imports = _download_additional_modules(\n\u001b[0m\u001b[0;32m    490\u001b[0m             \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mbase_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhf_hub_url\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrevision\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrevision\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Omar\\anaconda3\\lib\\site-packages\\evaluate\\loading.py\u001b[0m in \u001b[0;36m_download_additional_modules\u001b[1;34m(name, base_path, imports, download_config)\u001b[0m\n\u001b[0;32m    263\u001b[0m             \u001b[0mneeds_to_be_installed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlibrary_import_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlibrary_import_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mneeds_to_be_installed\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 265\u001b[1;33m         raise ImportError(\n\u001b[0m\u001b[0;32m    266\u001b[0m             \u001b[1;34mf\"To be able to use {name}, you need to install the following dependencies\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m             \u001b[1;34mf\"{[lib_name for lib_name, lib_path in needs_to_be_installed]} using 'pip install \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: To be able to use evaluate-metric/rouge, you need to install the following dependencies['absl', 'rouge_score'] using 'pip install # Here to have a nice missing dependency error message early on rouge_score' for instance'"
     ]
    }
   ],
   "source": [
    "import evaluate\n",
    "import numpy as np\n",
    "\n",
    "rouge = evaluate.load('rouge')\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    result = rouge.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
    "\n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "\n",
    "    return {k: round(v, 4) for k, v in result.items()}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"ouput-model\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=4,\n",
    "    predict_with_generate=True,\n",
    "    fp16=True\n",
    ")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=small_train_dataset[\"train\"],\n",
    "    eval_dataset=small_test_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
