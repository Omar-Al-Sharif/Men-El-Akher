{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datasets import load_dataset\n",
    "\n",
    "# dataset = load_dataset('OmarAboBakr/AIC_preprocessed_dataset')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset['train'].to_csv('train.csv')\n",
    "# dataset['validation'].to_csv('validation.csv')\n",
    "# dataset['test'].to_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (C:/Users/Omar/.cache/huggingface/datasets/csv/default-7c4767214f85e1d6/0.0.0/eea64c71ca8b46dd3f537ed218fc9bf495d5707789152eb2764f5c78fa66d59d)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63f730e9684f478a87fbd3854d41a8ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset('csv', data_files={'train':'train.csv', 'validation':'validation.csv', 'test':'test.csv'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'يعزا تراجع إيراد +ات ياهو ب+ شكل كبير إلى ال+ انخفاض ال+ حاد في نشاط ال+ إعلان +ات ال+ مرئي +ة ال+ رقمي +ة و+ تساعد ف+ ل+ اري مطور +ي ال+ تطبيق +ات على تحليل ال+ بيان +ات ال+ متعلق +ة ب+ مستخدمي +هم و+ توفير إعلان +ات تناسب أذواق +هم . و+ اشترى بعض منافس +ي ياهو شرك +ات تعمل في تكنولوجيا إعلان +ات ال+ هواتف ال+ محمول +ة في محاول +ة ل+ جذب ال+ مسوق +ين إلى تطبيق +ات +ها و+ تحقيق إيراد +ات من ال+ إعلان +ات على تطبيق +ات شرك +ات أخرى . و+ لم تكشف ال+ شركتان عن ال+ بنود ال+ مالي +ة ل+ صفق +ة ال+ استحواذ . لكن بعض ال+ تقارير أشار +ت إلى أن ياهو دفع +ت ما بين 200 و 300 مليون دولار ل+ ال+ استحواذ على ف+ ل+ اري ، ل+ تكون ب+ ذلك واحد +ة من أكبر عملي +ات ال+ استحواذ ل+ ياهو منذ أن استحوذ +ت على منص +ة تدوين \" تومبير \" عام 2012 . مواضيع قد تهم +ك نهاي +ة تعزيز ال+ إيراد +ات و+ تأتي صفق +ة ياهو ل+ ال+ استحواذ على ف+ ل+ اري بعد أيام فقط من إعلان تراجع أرباح +ها ب+ واقع 18 في ال+ مئ +ة إلى 270 مليون دولار خلال ال+ أشهر ال+ ثلاث +ة حتى نهاي +ة يونيو - حزيران ال+ ماضي . و+ تراجع +ت ال+ إيراد +ات أيض +ا في شرك +ة ال+ إنترنت ال+ عملاق +ة ب+ واقع ثلاث +ة في ال+ مئ +ة إلى 1 . 08 مليار دولار . و+ يعزا هذا ال+ تراجع ب+ شكل كبير إلى ال+ انخفاض ال+ حاد في نشاط ال+ إعلان +ات ال+ مرئي +ة ال+ رقمي +ة ، التي تراجع +ت ب+ واقع ثماني +ة في ال+ مئ +ة في ال+ ربع ال+ ثاني . لكن ياهو قال +ت إن إيراد +ات إعلان +ات ال+ هواتف ال+ محمول +ة و+ أنشط +ة ال+ بحث زاد كل من +ها ب+ أكثر من 100 في ال+ مئ +ة خلال هذه ال+ فتر +ة مقارن +ة ب+ ال+ عام ال+ سابق . و+ قال +ت ال+ شركتان ال+ اثنين إن +ه من خلال اندماج +هما مع +ا ف+ س+ يكونان أكثر قدر +ة على خدم +ة عملائ +هما ب+ صور +ة أفضل و+ تعزيز إيراد +ات ال+ إعلان +ات . ماريسا ماير ال+ رئيس +ة ال+ تنفيذي +ة ل+ ياهو تقول إن ال+ شرك +ة تحتاج ل+ ال+ عمل ب+ جد ل+ وقف تراجع إيراد +ات ال+ إعلان +ات ال+ تركيز على ال+ هواتف ال+ محمول +ة و+ قال سيمون خلف ال+ رئيس ال+ تنفيذي ل+ شرك +ة ف+ ل+ اري في بيان ل+ +ه إن +ه \" ب+ ال+ تعاون مع ياهو ، س+ يكون ب+ إمكان +نا ال+ استفاد +ة من ال+ مزيد من ال+ موارد ل+ تسريع تقديم منتج +ات رائع +ة يمكن أن تساعد ال+ مطور +ين على ابتكار تطبيق +ات أفضل و+ ال+ وصول إلى ال+ مستخدم +ين ال+ مناسب +ين و+ اكتشاف فرص جديد +ة ل+ تحقيق ال+ إيراد +ات \" . و+ ب+ حسب موقع ف+ ل+ اري على ال+ إنترنت ، ف+ إن +ها تعمل مع أكثر من 170 ألف مطور يحصل +ون على بيان +ات من خلال متابع +ة 150 مليار من اتصال +ات ال+ تطبيق +ات شهري +ا ل+ توفير معلوم +ات ل+ شرك +ات نشر ال+ تطبيق +ات تتعلق ب+ جمهور +ها و+ استخدام ال+ تطبيق و+ مستوى أدائ +ه . و+ تزايد ال+ طلب ال+ عالمي على ال+ هواتف ال+ محمول +ة خلال ال+ سنو +ات ال+ أخير +ة و+ تزايد عدد ال+ أشخاص الذين يدخل +ون إلى ال+ إنترنت من خلال هواتف +هم ال+ ذكي +ة في مقابل أجهز +ة ال+ كمبيوتر ال+ شخصي +ة ال+ تقليدي +ة . و+ دفع هذا شرك +ات ال+ إنترنت مثل ياهو و+ تويتر و+ غوغل و+ فيسبوك ل+ تطوير إستراتيجي +ات ل+ زياد +ة إيراد +ات +ها من ال+ هواتف ال+ محمول +ة .',\n",
       " 'summary': 'استحوذ +ت شرك +ة ياهو على شرك +ة ف+ ل+ اري ل+ تحليل ال+ تطبيق +ات ل+ ال+ مساعد +ة في تعزيز عائد +ات +ها من ال+ إعلان +ات من ال+ هواتف ال+ ذكي +ة .'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "# from arabert.preprocess import ArabertPreprocessor\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = \"aubmindlab/bert-base-arabertv2\"\n",
    "# preprocessor = ArabertPreprocessor(model_name=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def preprocess_function(text):\n",
    "#   return preprocessor.preprocess(text)\n",
    "\n",
    "# import re\n",
    "\n",
    "# def unpreprocess_function(text):\n",
    "#   temp = preprocessor.unpreprocess(text)\n",
    "#   temp = re.sub('\\[CLS\\]|\\[PAD\\]|\\[SEP\\]', '', temp)\n",
    "#   return re.sub('\\s+$|^\\s', '', temp)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"./AraT5\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"./AraT5\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encode the dataset with the tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datasets\n",
    "train_df = pd.DataFrame(dataset['train'])\n",
    "test_df = pd.DataFrame(dataset['test'])\n",
    "val_df = pd.DataFrame(dataset['validation'])\n",
    "test_df = test_df.dropna()\n",
    "train_df = train_df.dropna()\n",
    "val_df = val_df.dropna()\n",
    "train_dataset = datasets.Dataset.from_dict(train_df)\n",
    "test_dataset = datasets.Dataset.from_dict(test_df)\n",
    "val_dataset = datasets.Dataset.from_dict(val_df)\n",
    "dataset = datasets.DatasetDict({\"train\":train_dataset,\"test\":test_dataset,\"validation\":val_dataset})\n",
    "\n",
    "\n",
    "del train_df\n",
    "del test_df\n",
    "del val_df\n",
    "del train_dataset\n",
    "del test_dataset\n",
    "del val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_input_length = 1024\n",
    "# max_length=1024\n",
    "max_target_length = 128\n",
    "\n",
    "# i=0\n",
    "\n",
    "def tokenize_function(examples):\n",
    "  # global i\n",
    "  # i+=1\n",
    "  # inputs = [preprocess_function(text) for text in examples['text']]\n",
    "  \n",
    "  model_inputs = tokenizer(examples['text'], padding='max_length', truncation=True)\n",
    "  # print('check1', i)\n",
    "\n",
    "\n",
    "  labels = tokenizer(examples['summary'], padding='max_length', max_length=128, truncation=True, return_tensors=\"pt\")\n",
    "  # print('check2', i)\n",
    "\n",
    "  model_inputs['labels'] = labels['input_ids']\n",
    "  return model_inputs\n",
    "\n",
    "\n",
    "# def tokenize_function(examples):\n",
    "#   inputs = examples['text']\n",
    "#   model_inputs = tokenizer(inputs, padding='max_length', truncation=True)\n",
    "\n",
    "#   labels = tokenizer(examples['summary'], padding='max_length', max_length=128, truncation=True)\n",
    "\n",
    "#   model_inputs['labels'] = labels['input_ids']\n",
    "#   return model_inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77978e8f4151405798ce805fc2d3d2d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/60875 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to pad to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no padding.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acb22f9d86f94c93bd77bc07c68a30a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7610 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d31a5b4cd1894d23837b0e26489632ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7610 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "\n",
    "small_train_dataset = tokenized_dataset[\"train\"].shuffle(seed=42).select(range(1000))\n",
    "small_test_dataset = tokenized_dataset[\"test\"].shuffle(seed=42).select(range(1000))\n",
    "\n",
    "del tokenized_dataset\n",
    "del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# print(sys.getdefaultencoding())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "import numpy as np\n",
    "\n",
    "rouge = evaluate.load('rouge')\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    result = rouge.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
    "\n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "\n",
    "    return {k: round(v, 4) for k, v in result.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1180"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"finetuned-model\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=4,\n",
    "    predict_with_generate=True\n",
    "    # fp16=True\n",
    ")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=small_train_dataset,\n",
    "    eval_dataset=small_test_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
